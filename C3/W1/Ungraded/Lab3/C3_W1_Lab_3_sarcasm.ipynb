{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNfIki8Uf06wRz5HYeu9dD+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Ungraded Lab: Tokenizing the Sarcasm Dataset\n","\n","In this lab, you will apply what you've learned in the past two exercises to preprocess the [News Headlines Dataset for Sarcasm Detection](https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection). This contains news headlines which are labeled as sarcastic or not. You will revisit this dataset in later labs so it is good to be acquainted with it now.\n","\n","**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running it on your local machine might result in some of the code blocks throwing errors."],"metadata":{"id":"Ha9ngzf9SP2I"}},{"cell_type":"markdown","source":["## Download and inspect the dataset\n","\n","First, you will fetch the dataset and preview some of its elements."],"metadata":{"id":"EU9AtCoCSaJW"}},{"cell_type":"code","source":["import os\n","try:\n","    import wget\n","except ModuleNotFoundError:\n","    print(\"Installing wget module...\")\n","    !pip install wget\n","    import wget\n","\n","def download_dataset(url, folder, filename):\n","    # Check if the folder exists, otherwise, create it\n","    if not os.path.exists(folder):\n","        os.makedirs(folder)\n","\n","    file_path = os.path.join(folder, filename)\n","\n","    # Check if the file has already been downloaded\n","    if not os.path.exists(file_path):\n","        print(f\"Downloading file from {url}...\")\n","        wget.download(url, out=folder)\n","        print(\"\\nDownload completed.\")\n","    else:\n","        print(\"The file has already been downloaded.\")\n","\n","# Specify the URL of the file, the destination folder, and the filename\n","url = \"https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\"\n","folder = \"Datasets\"\n","filename = \"sarcasm.json\"\n","\n","# Call the function to download the file.\n","download_dataset(url, folder, filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_DPsUp-5TGT2","executionInfo":{"status":"ok","timestamp":1739971424425,"user_tz":300,"elapsed":6297,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"db8d10bb-eff5-479a-e310-19f537af30be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing wget module...\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=781ccd042ecda2efed63b378625919c906ef2a2270b6755d74944954c00b7cde\n","  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","Downloading file from https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json...\n","\n","Download completed.\n"]}]},{"cell_type":"markdown","source":["The dataset is saved as a [JSON](https://www.json.org/json-en.html) file and you can use Python's [`json`](https://docs.python.org/3/library/json.html) module to load it into your workspace. The cell below unpacks the JSON file into a list."],"metadata":{"id":"QBGQ8dlcYgVs"}},{"cell_type":"code","source":["import json\n","\n","def load_json_file(file_path):\n","    with open(file_path, 'r') as f:\n","        json_data = json.load(f)\n","    return json_data\n","\n","# Example usage\n","datastore = load_json_file(\"./Datasets/sarcasm.json\")"],"metadata":{"id":"jNjedyj9YhtL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can inspect a few of the elements in the list. You will notice that each element consists of a dictionary with a URL link, the actual headline, and a label named `is_sarcastic`. Printed below are two elements with contrasting labels."],"metadata":{"id":"a62KbC9lZBHL"}},{"cell_type":"code","source":["# Print the JSON data in a readable format\n","print(json.dumps(datastore, indent=4))"],"metadata":{"id":"M4l7kq56acb4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 'datastore' is your array of JSON Objects\n","article = 20000\n","\n","# Print the article link, the headline, and whether it is sarcastic or not\n","print(\"Article Link:\", datastore[article][\"article_link\"])\n","print(\"Headline:\", datastore[article][\"headline\"])\n","print(\"Is Sarcastic:\", \"Yes\" if datastore[article][\"is_sarcastic\"] == 1 else \"No\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OnNmIOrFbzgd","executionInfo":{"status":"ok","timestamp":1739972886364,"user_tz":300,"elapsed":52,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"94604a7e-534c-4c49-89d3-f95d6c752c9d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Article Link: https://www.theonion.com/pediatricians-announce-2011-newborns-are-ugliest-babies-1819572977\n","Headline: pediatricians announce 2011 newborns are ugliest babies in 30 years\n","Is Sarcastic: Yes\n"]}]},{"cell_type":"markdown","source":["With that, you can collect the headlines because those are the string inputs that you will preprocess into numeric features."],"metadata":{"id":"0mVUZeG5gmpu"}},{"cell_type":"code","source":["# Append the headline elements into the list\n","sentences = [item['headline'] for item in datastore]\n","print(f'There are {len(sentences)} headlines in the datastore')\n","print(f'First five headlines in the datastore: {sentences[:5]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnaRSx83dElE","executionInfo":{"status":"ok","timestamp":1739973009009,"user_tz":300,"elapsed":8,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"4872724f-182a-4175-84ff-0c565fc48c86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 26709 headlines in the datastore\n","First five headlines in the datastore: [\"former versace store clerk sues over secret 'black code' for minority shoppers\", \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", \"mom starting to fear son's web series closest thing she will have to grandchild\", 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas', 'j.k. rowling wishes snape happy birthday in the most magical way']\n"]}]},{"cell_type":"markdown","source":["## Preprocessing the headlines\n","\n","You can convert the sentences list above into padded sequences by using the same methods you've been using in the previous labs. The cells below will build the vocabulary, then use that to generate the list of post-padded sequences for each of the 26,709 headlines."],"metadata":{"id":"g31YIfJ_dOw6"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Instantiate the layer\n","vectorize_layer = tf.keras.layers.TextVectorization()\n","\n","# Build the vocabulary\n","vectorize_layer.adapt(sentences)\n","\n","# Apply the layer for post padding\n","post_padded_sequences = vectorize_layer(sentences)"],"metadata":{"id":"1NnxEJCseUvJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can view the results for a particular headline by changing the value of `index` below."],"metadata":{"id":"qmt0YtEBew4Q"}},{"cell_type":"code","source":["# Print dimensions of padded sequences\n","print(f'Shape of padded sequences: {post_padded_sequences.shape}')\n","\n","# Print a sample headline and sequence\n","index = 20000\n","print(f'sample headline: {sentences[index]}')\n","print(f'padded sequence: {post_padded_sequences[index]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NqLrBC6vhl_G","executionInfo":{"status":"ok","timestamp":1739973982328,"user_tz":300,"elapsed":20,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"406effbf-b6e3-4af2-ff5e-c4a090dba3fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of padded sequences: (26709, 39)\n","sample headline: pediatricians announce 2011 newborns are ugliest babies in 30 years\n","padded sequence: [11985  1123  6846  5432    30  8441  2365     5   690    84     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0]\n"]}]},{"cell_type":"markdown","source":["For prepadding, you have to setup the `TextVectorization` layer differently. You don't want to have the automatic postpadding shown above, and instead have sequences with variable length. Then, you will pass it to the `pad_sequences()` utility function you used in the previous lab. The cells below show one way to do it:\n","\n","* First, you will initialize the `TextVectorization` layer and set its `ragged` flag to `True`. This will result in a [ragged tensor](https://www.tensorflow.org/guide/ragged_tensor) which simply means a tensor with variable-length elements. The sequences will indeed have different lengths after removing the zeroes, thus you will need the ragged tensor to contain them.\n","\n","* Like before, you will use the layer's `adapt()` method to generate a vocabulary.\n","\n","* Then, you will apply the layer to the string sentences to generate the integer sequences. As mentioned, this will not be post-padded.\n","\n","* Lastly, you will pass this ragged tensor to the [pad_sequences()](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences) function to generate pre-padded sequences."],"metadata":{"id":"odmpspUDiO3A"}},{"cell_type":"code","source":["# Instantiate the layer and set the `ragged` flag to `True`\n","vectorize_layer = tf.keras.layers.TextVectorization(ragged=True)\n","\n","# Build the vocabulary\n","vectorize_layer.adapt(sentences)\n","\n","# Apply the layer to generate a ragged tensor\n","ragged_sequences = vectorize_layer(sentences)"],"metadata":{"id":"X6rf3CGZiP0q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print dimensions of padded sequences\n","print(f'Shape of padded sequences: {ragged_sequences.shape}')\n","\n","# Print a sample headline and sequence\n","index = 20000\n","print(f'sample headline: {sentences[index]}')\n","print(f'padded sequence: {ragged_sequences[index]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I_2xYyBKiwhI","executionInfo":{"status":"ok","timestamp":1739974323629,"user_tz":300,"elapsed":61,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"7d334ec6-ee7b-4be1-ca8f-28e529e4a1e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of padded sequences: (26709, None)\n","sample headline: pediatricians announce 2011 newborns are ugliest babies in 30 years\n","padded sequence: [11985  1123  6846  5432    30  8441  2365     5   690    84]\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.utils import pad_sequences\n","\n","# Apply pre-padding to the ragged tensor\n","pre_padded_sequences = pad_sequences(ragged_sequences.numpy())\n","print(f'Shape of pre-padded sequences: {pre_padded_sequences.shape}')\n","\n","# Preview the result for an only sequence\n","index = 2\n","print(f'sample headline: {sentences[index]}')\n","print(f'padded sequence: {pre_padded_sequences[index]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_0pxOIAjY-R","executionInfo":{"status":"ok","timestamp":1739974855050,"user_tz":300,"elapsed":69,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"1df3de81-68de-4c7a-f778-a3420d641bf1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of pre padded sequences: (26709, 39)\n","sample headline: mom starting to fear son's web series closest thing she will have to grandchild\n","padded sequence: [    0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0   140   825     2   813  1100  2048   571  5057   199   139    39\n","    46     2 13050]\n"]}]},{"cell_type":"markdown","source":["You can see the results for post-padded and pre-padded sequences by changing the value of `index` below."],"metadata":{"id":"ZZ48Dea3k3Nx"}},{"cell_type":"code","source":["# Print a sample headline and sequence\n","index = 2\n","print(f'sample headline: {sentences[index]}')\n","print()\n","print(f'post-padded sequence: {post_padded_sequences[index]}')\n","print()\n","print(f'pre-padded sequence: {pre_padded_sequences[index]}')\n","print()\n","\n","# Print dimensions of padded sequences\n","print(f'shape of post-padded sequences: {post_padded_sequences.shape}')\n","print(f'shape of pre-padded sequences: {pre_padded_sequences.shape}')\n","print()\n","\n","print(f'The dimensions of sequences with pre-padded and post-padded are equal: {post_padded_sequences.shape==pre_padded_sequences.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SuKB4jIk5A1","executionInfo":{"status":"ok","timestamp":1739975101185,"user_tz":300,"elapsed":8,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"dea062ff-3840-4b19-de25-b187ca1e304f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample headline: mom starting to fear son's web series closest thing she will have to grandchild\n","\n","post-padded sequence: [  140   825     2   813  1100  2048   571  5057   199   139    39    46\n","     2 13050     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0]\n","\n","pre-padded sequence: [    0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0   140   825     2   813  1100  2048   571  5057   199   139    39\n","    46     2 13050]\n","\n","shape of post-padded sequences: (26709, 39)\n","shape of pre-padded sequences: (26709, 39)\n","\n","The dimensions of sequences with pre-padded and post-padded are equal: True\n"]}]},{"cell_type":"markdown","source":["This concludes the short demo on text data preprocessing on a relatively large dataset. Next week, you will start building models that can be trained on these output sequences. See you there!"],"metadata":{"id":"oOHZE1TqldWe"}}]}