{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPlWZ+eUrKdS1Eon0+Q+27"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Ungraded Lab: Building a Vocabulary\n","\n","In most natural language processing (NLP) tasks, the initial step in preparing your data is to extract a vocabulary of words from your corpus (i.e. input texts). You will need to define how to represent the texts into numeric features which can be used to train a neural network. Tensorflow and Keras makes it easy to generate these using its APIs. You will see how to do that in the next cells.\n","\n","**IMPORTANT NOTE:** This notebook is designed to run as a Colab. Running it on your local machine might result in some of the code blocks throwing errors."],"metadata":{"id":"FX4eNAgqw1wZ"}},{"cell_type":"markdown","source":["The code below takes a list of sentences, then takes each word in those sentences and assigns it to an integer. This is done using the [TextVectorization()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) preprocessing layer and its [adapt()](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization#adapt) method.\n","\n","As mentioned in the docs above, this layer does several things including:\n","\n","1. Standardizing each example. The default behavior is to lowercase and strip punctuation. See its `standardize` argument for other options.\n","2. Splitting each example into substrings. By default, it will split into words. See its `split` argument for other options.\n","3. Recombining substrings into tokens. See its `ngrams` argument for reference.\n","4. Indexing tokens.\n","5. Transforming each example using this index, either into a vector of ints or a dense float vector.\n","\n","Run the cells below to see this in action."],"metadata":{"id":"Ll6-IHxlxlVb"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Sample inputs\n","sentences = [\n","    'i love my dog',\n","    'I, love my cat'\n","    ]\n","\n","# Initialize the layer\n","vectorize_layer = tf.keras.layers.TextVectorization()\n","\n","# Build the vocabulary\n","vectorize_layer.adapt(sentences)\n","\n","# Get the vocabulary list. Ignore special tokens for now.\n","vocabulary = vectorize_layer.get_vocabulary(include_special_tokens=False)"],"metadata":{"id":"gEXUcYcSxpDz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The resulting `vocabulary` will be a list where more frequently used words will have a lower index. By default, it will also reserve indices for special tokens but , for clarity, let's reserve that for later."],"metadata":{"id":"gte8OAVIyeE7"}},{"cell_type":"code","source":["# Print the token index\n","for index, word in enumerate(vocabulary):\n","  print(index, word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JS_b7oFnyk9D","executionInfo":{"status":"ok","timestamp":1739794559012,"user_tz":240,"elapsed":4,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"99180744-8f01-49db-cb1d-c5fd5dc13eef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 my\n","1 love\n","2 i\n","3 dog\n","4 cat\n"]}]},{"cell_type":"markdown","source":["If you add another sentence, you'll notice new words in the vocabulary and new punctuation is still ignored as expected."],"metadata":{"id":"saeTEKlAys3c"}},{"cell_type":"code","source":["# Add another input\n","sentences = [\n","    'i love my dog',\n","    'I, love my cat',\n","    'You love my dog!'\n","]\n","\n","# Initialize the layer\n","vectorize_layer = tf.keras.layers.TextVectorization()\n","\n","# Build the vocabulary\n","vectorize_layer.adapt(sentences)\n","\n","# Get the vocabulary list. Ignore special tokens for now.\n","vocabulary = vectorize_layer.get_vocabulary(include_special_tokens=False)"],"metadata":{"id":"PKGCR3iNyt47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the token index\n","for index, word in enumerate(vocabulary):\n","  print(index, word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x6K4nzkDy4WD","executionInfo":{"status":"ok","timestamp":1739794559583,"user_tz":240,"elapsed":4,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"84c9d2eb-9ccf-4e7b-de6f-ebd7224db90f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 my\n","1 love\n","2 i\n","3 dog\n","4 you\n","5 cat\n"]}]},{"cell_type":"markdown","source":["Now that you see how it behaves, let's include the two special tokens. The first one at `0` is used for padding and `1` is used for out-of-vocabulary words. These are important when you use the layer to convert input texts to integer sequences. You'll see that in the next lab."],"metadata":{"id":"dGXQ3KrXy3YD"}},{"cell_type":"code","source":["# Get the vocabulary list.\n","vocabulary = vectorize_layer.get_vocabulary()\n","\n","# Print the token index\n","for index, word in enumerate(vocabulary):\n","  print(index, word)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L07SMZEey-_z","executionInfo":{"status":"ok","timestamp":1739794562890,"user_tz":240,"elapsed":4,"user":{"displayName":"Luis Alfredo Hung Araque","userId":"00964424177241549147"}},"outputId":"33115e9f-c3d0-44a5-a508-7c3793cc7b94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 \n","1 [UNK]\n","2 my\n","3 love\n","4 i\n","5 dog\n","6 you\n","7 cat\n"]}]},{"cell_type":"markdown","source":["That concludes this short exercise on building a vocabulary!"],"metadata":{"id":"w_oxYbNRzEYj"}}]}